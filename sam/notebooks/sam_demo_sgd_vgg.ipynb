{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f35b564",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from model.vgg import VGG\n",
    "from model.smooth_cross_entropy import smooth_crossentropy\n",
    "from data.cifar import Cifar\n",
    "from utility.log import Log\n",
    "from utility.step_lr import StepLR\n",
    "from utility.bypass_bn import enable_running_stats, disable_running_stats\n",
    "\n",
    "import sys; sys.path.append(\"..\")\n",
    "from sam import SAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c588d070",
   "metadata": {},
   "outputs": [],
   "source": [
    "adaptive =  True\n",
    "batch_size = 128\n",
    "depth = 16\n",
    "dropout = 0.0\n",
    "epochs = 200\n",
    "label_smoothing = 0.1\n",
    "learning_rate = 0.001\n",
    "momentum= 0.9\n",
    "threads = 5\n",
    "rho = 2.0\n",
    "weight_decay = 0.0005\n",
    "width_factor = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c008c045",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize(seed: int):\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    torch.backends.cudnn.enabled = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cudnn.deterministic = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "892580fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "initialize(seed=0)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7dd42d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "dataset = Cifar(batch_size, threads)\n",
    "log = Log(log_each=10)\n",
    "model = VGG('VGG16').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95c4e298",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_optimizer = torch.optim.Adam\n",
    "optimizer = SAM(model.parameters(), base_optimizer, rho=rho, adaptive=adaptive, lr=learning_rate, weight_decay=weight_decay)\n",
    "scheduler = StepLR(optimizer, learning_rate, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2748aff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = np.zeros(epochs)\n",
    "train_accuracy = np.zeros(epochs)\n",
    "val_losses = np.zeros(epochs)\n",
    "val_accuracy = np.zeros(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "527b223d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┏━━━━━━━━━━━━━━┳━━━━━━━╸T╺╸R╺╸A╺╸I╺╸N╺━━━━━━━┳━━━━━━━╸S╺╸T╺╸A╺╸T╺╸S╺━━━━━━━┳━━━━━━━╸V╺╸A╺╸L╺╸I╺╸D╺━━━━━━━┓\n",
      "┃              ┃              ╷              ┃              ╷              ┃              ╷              ┃\n",
      "┃       epoch  ┃        loss  │    accuracy  ┃        l.r.  │     elapsed  ┃        loss  │    accuracy  ┃\n",
      "┠──────────────╂──────────────┼──────────────╂──────────────┼──────────────╂──────────────┼──────────────┨\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\enosh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:780: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.\n",
      "  warnings.warn(\"Note that order of the arguments: ceil_mode and return_indices will change\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┃           0  ┃      1.3291  │     32.83 %  ┃   1.000e-03  │   01:11 min  ┃┈██████████████████████████▓┈┨1.3291 32.83\n",
      "0.0 0.0\n",
      "      1.2089  │     39.59 %  ┃\n",
      "┃           1  ┃      1.0204  │     50.98 %  ┃   1.000e-03  │   01:13 min  ┃┈██████████████████████████▓┈┨1.0204 50.98\n",
      "1.2089 39.59\n",
      "      0.9340  │     56.63 %  ┃\n",
      "┃           2  ┃      0.8653  │     59.62 %  ┃   1.000e-03  │   02:06 min  ┃┈██████████████████████████▓┈┨0.8653 59.62\n",
      "0.934 56.63\n",
      "      1.0102  │     53.28 %  ┃\n",
      "┃           3  ┃      0.7757  │     63.52 %  ┃   1.000e-03  │   00:39 min  ┠┈████████░┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┨"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [8]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     16\u001B[0m disable_running_stats(model)\n\u001B[0;32m     17\u001B[0m smooth_crossentropy(model(inputs), targets, smoothing\u001B[38;5;241m=\u001B[39mlabel_smoothing)\u001B[38;5;241m.\u001B[39mmean()\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[1;32m---> 18\u001B[0m \u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msecond_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43mzero_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m     20\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m     21\u001B[0m     correct \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39margmax(predictions\u001B[38;5;241m.\u001B[39mdata, \u001B[38;5;241m1\u001B[39m) \u001B[38;5;241m==\u001B[39m targets\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\autograd\\grad_mode.py:27\u001B[0m, in \u001B[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     24\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[0;32m     25\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m     26\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclone():\n\u001B[1;32m---> 27\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mD:\\mini-project\\sam-main\\example\\..\\sam.py:35\u001B[0m, in \u001B[0;36mSAM.second_step\u001B[1;34m(self, zero_grad)\u001B[0m\n\u001B[0;32m     32\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m p\u001B[38;5;241m.\u001B[39mgrad \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m: \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[0;32m     33\u001B[0m         p\u001B[38;5;241m.\u001B[39mdata \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate[p][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mold_p\u001B[39m\u001B[38;5;124m\"\u001B[39m]  \u001B[38;5;66;03m# get back to \"w\" from \"w + e(w)\"\u001B[39;00m\n\u001B[1;32m---> 35\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbase_optimizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# do the actual \"sharpness-aware\" update\u001B[39;00m\n\u001B[0;32m     37\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m zero_grad: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mzero_grad()\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\optim\\optimizer.py:88\u001B[0m, in \u001B[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     86\u001B[0m profile_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOptimizer.step#\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m.step\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(obj\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m)\n\u001B[0;32m     87\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mautograd\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mrecord_function(profile_name):\n\u001B[1;32m---> 88\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\autograd\\grad_mode.py:27\u001B[0m, in \u001B[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     24\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[0;32m     25\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m     26\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclone():\n\u001B[1;32m---> 27\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\optim\\adam.py:141\u001B[0m, in \u001B[0;36mAdam.step\u001B[1;34m(self, closure)\u001B[0m\n\u001B[0;32m    138\u001B[0m             \u001B[38;5;66;03m# record the step after step update\u001B[39;00m\n\u001B[0;32m    139\u001B[0m             state_steps\u001B[38;5;241m.\u001B[39mappend(state[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstep\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m--> 141\u001B[0m     \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madam\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparams_with_grad\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    142\u001B[0m \u001B[43m           \u001B[49m\u001B[43mgrads\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    143\u001B[0m \u001B[43m           \u001B[49m\u001B[43mexp_avgs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    144\u001B[0m \u001B[43m           \u001B[49m\u001B[43mexp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    145\u001B[0m \u001B[43m           \u001B[49m\u001B[43mmax_exp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    146\u001B[0m \u001B[43m           \u001B[49m\u001B[43mstate_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    147\u001B[0m \u001B[43m           \u001B[49m\u001B[43mamsgrad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mamsgrad\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    148\u001B[0m \u001B[43m           \u001B[49m\u001B[43mbeta1\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta1\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    149\u001B[0m \u001B[43m           \u001B[49m\u001B[43mbeta2\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta2\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    150\u001B[0m \u001B[43m           \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mlr\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    151\u001B[0m \u001B[43m           \u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mweight_decay\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    152\u001B[0m \u001B[43m           \u001B[49m\u001B[43meps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43meps\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    153\u001B[0m \u001B[43m           \u001B[49m\u001B[43mmaximize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmaximize\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    154\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m loss\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\optim\\_functional.py:105\u001B[0m, in \u001B[0;36madam\u001B[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001B[0m\n\u001B[0;32m    103\u001B[0m     denom \u001B[38;5;241m=\u001B[39m (max_exp_avg_sqs[i]\u001B[38;5;241m.\u001B[39msqrt() \u001B[38;5;241m/\u001B[39m math\u001B[38;5;241m.\u001B[39msqrt(bias_correction2))\u001B[38;5;241m.\u001B[39madd_(eps)\n\u001B[0;32m    104\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 105\u001B[0m     denom \u001B[38;5;241m=\u001B[39m \u001B[43m(\u001B[49m\u001B[43mexp_avg_sq\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msqrt\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mmath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msqrt\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbias_correction2\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madd_\u001B[49m\u001B[43m(\u001B[49m\u001B[43meps\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    109\u001B[0m step_size \u001B[38;5;241m=\u001B[39m lr \u001B[38;5;241m/\u001B[39m bias_correction1\n\u001B[0;32m    110\u001B[0m param\u001B[38;5;241m.\u001B[39maddcdiv_(exp_avg, denom, value\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39mstep_size)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    log.train(len_dataset=len(dataset.train))\n",
    "\n",
    "    for batch in dataset.train:\n",
    "        inputs, targets = (b.to(device) for b in batch)\n",
    "\n",
    "        # first forward-backward step\n",
    "        enable_running_stats(model)\n",
    "        predictions = model(inputs)\n",
    "        loss = smooth_crossentropy(predictions, targets, smoothing=label_smoothing)\n",
    "        loss.mean().backward()\n",
    "        optimizer.first_step(zero_grad=True)\n",
    "\n",
    "        # second forward-backward step\n",
    "        disable_running_stats(model)\n",
    "        smooth_crossentropy(model(inputs), targets, smoothing=label_smoothing).mean().backward()\n",
    "        optimizer.second_step(zero_grad=True)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            correct = torch.argmax(predictions.data, 1) == targets\n",
    "            log(model, loss.cpu(), correct.cpu(), scheduler.lr())\n",
    "            scheduler(epoch)\n",
    "\n",
    "    model.eval()\n",
    "    train_losses[epoch], train_accuracy[epoch] = log.eval(len_dataset=len(dataset.test))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataset.test:\n",
    "            inputs, targets = (b.to(device) for b in batch)\n",
    "\n",
    "            predictions = model(inputs)\n",
    "            loss = smooth_crossentropy(predictions, targets)\n",
    "            correct = torch.argmax(predictions, 1) == targets\n",
    "            log(model, loss.cpu(), correct.cpu())\n",
    "        if epoch > 0:\n",
    "            val_losses[epoch-1] = log.current_valid_loss\n",
    "            val_accuracy[epoch-1] = log.current_valid_accuracy\n",
    "\n",
    "val_losses[epochs-1] = log.current_valid_loss\n",
    "val_accuracy[epochs-1] = log.current_valid_accuracy\n",
    "log.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f6018d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'sam_model_sgd_vgg.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(range(1, epochs + 1), train_losses, label='Train loss')\n",
    "plt.plot(range(1, epochs + 1), val_losses, label='Validation loss')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(range(1, epochs + 1), train_accuracy, label='Train Accuracy')\n",
    "plt.plot(range(1, epochs + 1), val_accuracy, label='Train Accuracy')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}