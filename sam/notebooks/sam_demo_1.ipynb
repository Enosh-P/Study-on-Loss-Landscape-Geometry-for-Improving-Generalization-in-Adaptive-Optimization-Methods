{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a1dc2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import random\n",
    "\n",
    "from utility.log import Log\n",
    "from model.resnet import ResNet18"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b572f75c",
   "metadata": {},
   "source": [
    "### Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "488aafb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicUnit(nn.Module):\n",
    "    def __init__(self, channels: int, dropout: float):\n",
    "        super(BasicUnit, self).__init__()\n",
    "        self.block = nn.Sequential(OrderedDict([\n",
    "            (\"0_normalization\", nn.BatchNorm2d(channels)),\n",
    "            (\"1_activation\", nn.ReLU(inplace=True)),\n",
    "            (\"2_convolution\", nn.Conv2d(channels, channels, (3, 3), stride=1, padding=1, bias=False)),\n",
    "            (\"3_normalization\", nn.BatchNorm2d(channels)),\n",
    "            (\"4_activation\", nn.ReLU(inplace=True)),\n",
    "            (\"5_dropout\", nn.Dropout(dropout, inplace=True)),\n",
    "            (\"6_convolution\", nn.Conv2d(channels, channels, (3, 3), stride=1, padding=1, bias=False)),\n",
    "        ]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.block(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58cb0a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownsampleUnit(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, stride: int, dropout: float):\n",
    "        super(DownsampleUnit, self).__init__()\n",
    "        self.norm_act = nn.Sequential(OrderedDict([\n",
    "            (\"0_normalization\", nn.BatchNorm2d(in_channels)),\n",
    "            (\"1_activation\", nn.ReLU(inplace=True)),\n",
    "        ]))\n",
    "        self.block = nn.Sequential(OrderedDict([\n",
    "            (\"0_convolution\", nn.Conv2d(in_channels, out_channels, (3, 3), stride=stride, padding=1, bias=False)),\n",
    "            (\"1_normalization\", nn.BatchNorm2d(out_channels)),\n",
    "            (\"2_activation\", nn.ReLU(inplace=True)),\n",
    "            (\"3_dropout\", nn.Dropout(dropout, inplace=True)),\n",
    "            (\"4_convolution\", nn.Conv2d(out_channels, out_channels, (3, 3), stride=1, padding=1, bias=False)),\n",
    "        ]))\n",
    "        self.downsample = nn.Conv2d(in_channels, out_channels, (1, 1), stride=stride, padding=0, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.norm_act(x)\n",
    "        return self.block(x) + self.downsample(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60b3e17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, stride: int, depth: int, dropout: float):\n",
    "        super(Block, self).__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            DownsampleUnit(in_channels, out_channels, stride, dropout),\n",
    "            *(BasicUnit(out_channels, dropout) for _ in range(depth))\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b883b1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideResNet(nn.Module):\n",
    "    def __init__(self, depth: int, width_factor: int, dropout: float, in_channels: int, labels: int):\n",
    "        super(WideResNet, self).__init__()\n",
    "\n",
    "        self.filters = [16, 1 * 16 * width_factor, 2 * 16 * width_factor, 4 * 16 * width_factor]\n",
    "        self.block_depth = (depth - 4) // (3 * 2)\n",
    "\n",
    "        self.f = nn.Sequential(OrderedDict([\n",
    "            (\"0_convolution\", nn.Conv2d(in_channels, self.filters[0], (3, 3), stride=1, padding=1, bias=False)),\n",
    "            (\"1_block\", Block(self.filters[0], self.filters[1], 1, self.block_depth, dropout)),\n",
    "            (\"2_block\", Block(self.filters[1], self.filters[2], 2, self.block_depth, dropout)),\n",
    "            (\"3_block\", Block(self.filters[2], self.filters[3], 2, self.block_depth, dropout)),\n",
    "            (\"4_normalization\", nn.BatchNorm2d(self.filters[3])),\n",
    "            (\"5_activation\", nn.ReLU(inplace=True)),\n",
    "            (\"6_pooling\", nn.AvgPool2d(kernel_size=8)),\n",
    "            (\"7_flattening\", nn.Flatten()),\n",
    "            (\"8_classification\", nn.Linear(in_features=self.filters[3], out_features=labels)),\n",
    "        ]))\n",
    "\n",
    "        self._initialize()\n",
    "\n",
    "    def _initialize(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight.data, mode=\"fan_in\", nonlinearity=\"relu\")\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                m.weight.data.zero_()\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.f(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318e17c1",
   "metadata": {},
   "source": [
    "### Smooth entropy done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "510467ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_crossentropy(pred, gold, smoothing=0.1):\n",
    "    n_class = pred.size(1)\n",
    "\n",
    "    one_hot = torch.full_like(pred, fill_value=smoothing / (n_class - 1))\n",
    "    one_hot.scatter_(dim=1, index=gold.unsqueeze(1), value=1.0 - smoothing)\n",
    "    log_prob = F.log_softmax(pred, dim=1)\n",
    "\n",
    "    return F.kl_div(input=log_prob, target=one_hot, reduction='none').sum(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e0400a",
   "metadata": {},
   "source": [
    "### Data Preparation done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fca0ded8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cutout:\n",
    "    def __init__(self, size=16, p=0.5):\n",
    "        self.size = size\n",
    "        self.half_size = size // 2\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, image):\n",
    "        if torch.rand([1]).item() > self.p:\n",
    "            return image\n",
    "\n",
    "        left = torch.randint(-self.half_size, image.size(1) - self.half_size, [1]).item()\n",
    "        top = torch.randint(-self.half_size, image.size(2) - self.half_size, [1]).item()\n",
    "        right = min(image.size(1), left + self.size)\n",
    "        bottom = min(image.size(2), top + self.size)\n",
    "\n",
    "        image[:, max(0, left): right, max(0, top): bottom] = 0\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70b9926a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cifar:\n",
    "    def __init__(self, batch_size, threads):\n",
    "        mean, std = self._get_statistics()\n",
    "\n",
    "        train_transform = transforms.Compose([\n",
    "            torchvision.transforms.RandomCrop(size=(32, 32), padding=4),\n",
    "            torchvision.transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean, std),\n",
    "            Cutout()\n",
    "        ])\n",
    "\n",
    "        test_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean, std)\n",
    "        ])\n",
    "\n",
    "        train_set = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transform)\n",
    "        test_set = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transform)\n",
    "\n",
    "        self.train = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=threads)\n",
    "        self.test = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=threads)\n",
    "\n",
    "        self.classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "    def _get_statistics(self):\n",
    "        train_set = torchvision.datasets.CIFAR10(root='./cifar', train=True, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "        data = torch.cat([d[0] for d in DataLoader(train_set)])\n",
    "        return data.mean(dim=[0, 2, 3]), data.std(dim=[0, 2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60717adc",
   "metadata": {},
   "source": [
    "### Step LR and Initialize and Bypass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d32d2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StepLR:\n",
    "    def __init__(self, optimizer, learning_rate: float, total_epochs: int):\n",
    "        self.optimizer = optimizer\n",
    "        self.total_epochs = total_epochs\n",
    "        self.base = learning_rate\n",
    "\n",
    "    def __call__(self, epoch):\n",
    "        if epoch < self.total_epochs * 3/10:\n",
    "            lr = self.base\n",
    "        elif epoch < self.total_epochs * 6/10:\n",
    "            lr = self.base * 0.2\n",
    "        elif epoch < self.total_epochs * 8/10:\n",
    "            lr = self.base * 0.2 ** 2\n",
    "        else:\n",
    "            lr = self.base * 0.2 ** 3\n",
    "\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            param_group[\"lr\"] = lr\n",
    "\n",
    "    def lr(self) -> float:\n",
    "        return self.optimizer.param_groups[0][\"lr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dce91b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize(seed: int):\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    torch.backends.cudnn.enabled = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cudnn.deterministic = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0c65cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def disable_running_stats(model):\n",
    "    def _disable(module):\n",
    "        if isinstance(module, nn.BatchNorm2d):\n",
    "            module.backup_momentum = module.momentum\n",
    "            module.momentum = 0\n",
    "\n",
    "    model.apply(_disable)\n",
    "\n",
    "def enable_running_stats(model):\n",
    "    def _enable(module):\n",
    "        if isinstance(module, nn.BatchNorm2d) and hasattr(module, \"backup_momentum\"):\n",
    "            module.momentum = module.backup_momentum\n",
    "\n",
    "    model.apply(_enable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0623d5",
   "metadata": {},
   "source": [
    "### SAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dcba7a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAM(torch.optim.Optimizer):\n",
    "    def __init__(self, params, base_optimizer, rho=0.05, adaptive=False, **kwargs):\n",
    "        assert rho >= 0.0, f\"Invalid rho, should be non-negative: {rho}\"\n",
    "\n",
    "        defaults = dict(rho=rho, adaptive=adaptive, **kwargs)\n",
    "        super(SAM, self).__init__(params, defaults)\n",
    "\n",
    "        self.base_optimizer = base_optimizer(self.param_groups, **kwargs)\n",
    "        self.param_groups = self.base_optimizer.param_groups\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def first_step(self, zero_grad=False):\n",
    "        grad_norm = self._grad_norm()\n",
    "        for group in self.param_groups:\n",
    "            scale = group[\"rho\"] / (grad_norm + 1e-12)\n",
    "\n",
    "            for p in group[\"params\"]:\n",
    "                if p.grad is None: continue\n",
    "                self.state[p][\"old_p\"] = p.data.clone()\n",
    "                e_w = (torch.pow(p, 2) if group[\"adaptive\"] else 1.0) * p.grad * scale.to(p)\n",
    "                p.add_(e_w)  # climb to the local maximum \"w + e(w)\"\n",
    "\n",
    "        if zero_grad: self.zero_grad()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def second_step(self, zero_grad=False):\n",
    "        for group in self.param_groups:\n",
    "            for p in group[\"params\"]:\n",
    "                if p.grad is None: continue\n",
    "                p.data = self.state[p][\"old_p\"]  # get back to \"w\" from \"w + e(w)\"\n",
    "\n",
    "        self.base_optimizer.step()  # do the actual \"sharpness-aware\" update\n",
    "\n",
    "        if zero_grad: self.zero_grad()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def step(self, closure=None):\n",
    "        assert closure is not None, \"Sharpness Aware Minimization requires closure, but it was not provided\"\n",
    "        closure = torch.enable_grad()(closure)  # the closure should do a full forward-backward pass\n",
    "\n",
    "        self.first_step(zero_grad=True)\n",
    "        closure()\n",
    "        self.second_step()\n",
    "\n",
    "    def _grad_norm(self):\n",
    "        shared_device = self.param_groups[0][\"params\"][0].device  # put everything on the same device, in case of model parallelism\n",
    "        norm = torch.norm(\n",
    "                    torch.stack([\n",
    "                        ((torch.abs(p) if group[\"adaptive\"] else 1.0) * p.grad).norm(p=2).to(shared_device)\n",
    "                        for group in self.param_groups for p in group[\"params\"]\n",
    "                        if p.grad is not None\n",
    "                    ]),\n",
    "                    p=2\n",
    "               )\n",
    "        return norm\n",
    "\n",
    "    def load_state_dict(self, state_dict):\n",
    "        super().load_state_dict(state_dict)\n",
    "        self.base_optimizer.param_groups = self.param_groups\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158db4bf",
   "metadata": {},
   "source": [
    "### Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6a4a56a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "adaptive = True\n",
    "batch_size = 32\n",
    "depth = 16\n",
    "dropout = 0.0\n",
    "label_smoothing = 0.1\n",
    "learning_rate = 0.001\n",
    "momentum = 0.9\n",
    "threads = 2\n",
    "rho = 2.0\n",
    "weight_decay = 0.0005\n",
    "width_factor = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a968a5cf",
   "metadata": {},
   "source": [
    "### Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "feedca1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "initialize(seed=42)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "01cee922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "dataset = Cifar(batch_size, threads)\n",
    "log = Log(log_each=10)\n",
    "# model = WideResNet(depth, width_factor, dropout, in_channels=3, labels=10).to(device)\n",
    "model = ResNet18(num_classes=10).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bdd06c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_optimizer = torch.optim.Adam\n",
    "# base_optimizer = torch.optim.SGD\n",
    "\n",
    "optimizer = SAM(\n",
    "    model.parameters(), \n",
    "    base_optimizer, \n",
    "    rho=rho, \n",
    "    adaptive=adaptive, \n",
    "    lr=learning_rate, \n",
    "    weight_decay=weight_decay\n",
    ")\n",
    "\n",
    "scheduler = StepLR(optimizer, learning_rate, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7288d9a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┏━━━━━━━━━━━━━━┳━━━━━━━╸T╺╸R╺╸A╺╸I╺╸N╺━━━━━━━┳━━━━━━━╸S╺╸T╺╸A╺╸T╺╸S╺━━━━━━━┳━━━━━━━╸V╺╸A╺╸L╺╸I╺╸D╺━━━━━━━┓\n",
      "┃              ┃              ╷              ┃              ╷              ┃              ╷              ┃\n",
      "┃       epoch  ┃        loss  │    accuracy  ┃        l.r.  │     elapsed  ┃        loss  │    accuracy  ┃\n",
      "┠──────────────╂──────────────┼──────────────╂──────────────┼──────────────╂──────────────┼──────────────┨\n",
      "PRINTING... torch.Size([32])\n",
      "PRINTING... torch.Size([32])\n",
      "PRINTING... torch.Size([32])\n",
      "PRINTING... torch.Size([32])\n",
      "PRINTING... torch.Size([32])\n",
      "PRINTING... torch.Size([32])\n",
      "PRINTING... torch.Size([32])\n",
      "PRINTING... torch.Size([32])\n",
      "PRINTING... torch.Size([32])\n",
      "┃           0  ┃      1.9756  │     17.36 %  ┃   1.000e-03  │   00:00 min  ┠┈░┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┨PRINTING... torch.Size([32])\n",
      "PRINTING... torch.Size([32])\n",
      "PRINTING... torch.Size([32])\n",
      "PRINTING... torch.Size([32])\n",
      "PRINTING... torch.Size([32])\n",
      "PRINTING... torch.Size([32])\n",
      "PRINTING... torch.Size([32])\n",
      "PRINTING... torch.Size([32])\n",
      "PRINTING... torch.Size([32])\n",
      "PRINTING... torch.Size([32])\n",
      "┃           0  ┃      1.7279  │     18.12 %  ┃   1.000e-03  │   00:01 min  ┠┈░┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┨PRINTING... torch.Size([32])\n",
      "PRINTING... torch.Size([32])\n",
      "PRINTING... torch.Size([32])\n",
      "PRINTING... torch.Size([32])\n",
      "PRINTING... torch.Size([32])\n",
      "PRINTING... torch.Size([32])\n",
      "PRINTING... torch.Size([32])\n",
      "PRINTING... torch.Size([32])\n",
      "PRINTING... torch.Size([32])\n",
      "PRINTING... torch.Size([32])\n",
      "┃           0  ┃      1.7052  │     16.56 %  ┃   1.000e-03  │   00:02 min  ┠┈▒┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┨PRINTING... torch.Size([32])\n",
      "PRINTING... torch.Size([32])\n",
      "PRINTING... torch.Size([32])\n",
      "PRINTING... torch.Size([32])\n",
      "PRINTING... torch.Size([32])\n",
      "PRINTING... torch.Size([32])\n",
      "PRINTING... torch.Size([32])\n",
      "PRINTING... torch.Size([32])\n",
      "PRINTING... torch.Size([32])\n",
      "PRINTING... torch.Size([32])\n",
      "┃           0  ┃      1.6258  │     19.38 %  ┃   1.000e-03  │   00:03 min  ┠┈▓┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┨PRINTING... torch.Size([32])\n",
      "PRINTING... torch.Size([32])\n",
      "PRINTING... torch.Size([32])\n",
      "PRINTING... torch.Size([32])\n",
      "PRINTING... torch.Size([32])\n",
      "PRINTING... torch.Size([32])\n",
      "PRINTING... torch.Size([32])\n",
      "PRINTING... torch.Size([32])\n",
      "PRINTING... torch.Size([32])\n",
      "PRINTING... torch.Size([32])\n",
      "┃           0  ┃      1.6184  │     20.00 %  ┃   1.000e-03  │   00:04 min  ┠┈▓┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┨PRINTING... torch.Size([32])\n",
      "PRINTING... torch.Size([32])\n",
      "PRINTING... torch.Size([32])\n",
      "PRINTING... torch.Size([32])\n",
      "PRINTING... torch.Size([32])\n",
      "PRINTING... torch.Size([32])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-24-d72f221d1e1f>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      8\u001B[0m         \u001B[0;31m# first forward-backward step\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      9\u001B[0m         \u001B[0menable_running_stats\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 10\u001B[0;31m         \u001B[0mpredictions\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     11\u001B[0m         \u001B[0mloss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0msmooth_crossentropy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpredictions\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtargets\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msmoothing\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mlabel_smoothing\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     12\u001B[0m         \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"PRINTING...\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mloss\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/nnti-project/lib/python3.7/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m    887\u001B[0m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    888\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 889\u001B[0;31m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    890\u001B[0m         for hook in itertools.chain(\n\u001B[1;32m    891\u001B[0m                 \u001B[0m_global_forward_hooks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Desktop/OptML_Project/sam/model/resnet.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     52\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     53\u001B[0m         \u001B[0mout\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mF\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrelu\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbn1\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconv1\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 54\u001B[0;31m         \u001B[0mout\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlayer1\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     55\u001B[0m         \u001B[0mout\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlayer2\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     56\u001B[0m         \u001B[0mout\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlayer3\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/nnti-project/lib/python3.7/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m    887\u001B[0m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    888\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 889\u001B[0;31m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    890\u001B[0m         for hook in itertools.chain(\n\u001B[1;32m    891\u001B[0m                 \u001B[0m_global_forward_hooks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/nnti-project/lib/python3.7/site-packages/torch/nn/modules/container.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    117\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    118\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mmodule\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 119\u001B[0;31m             \u001B[0minput\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodule\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    120\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    121\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/nnti-project/lib/python3.7/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m    887\u001B[0m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    888\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 889\u001B[0;31m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    890\u001B[0m         for hook in itertools.chain(\n\u001B[1;32m    891\u001B[0m                 \u001B[0m_global_forward_hooks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Desktop/OptML_Project/sam/model/resnet.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     23\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     24\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 25\u001B[0;31m         \u001B[0mout\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mF\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrelu\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbn1\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconv1\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     26\u001B[0m         \u001B[0mout\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbn2\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconv2\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     27\u001B[0m         \u001B[0mout\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshortcut\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/nnti-project/lib/python3.7/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m    884\u001B[0m             \u001B[0minput\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mbw_hook\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msetup_input_hook\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    885\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 886\u001B[0;31m         \u001B[0;32mif\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_C\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_get_tracing_state\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    887\u001B[0m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    888\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    log.train(len_dataset=len(dataset.train))\n",
    "    \n",
    "    for batch in dataset.train:\n",
    "        inputs, targets = (b.to(device) for b in batch)\n",
    "\n",
    "        # first forward-backward step\n",
    "        enable_running_stats(model)\n",
    "        predictions = model(inputs)\n",
    "        loss = smooth_crossentropy(predictions, targets, smoothing=label_smoothing)\n",
    "        loss.mean().backward()\n",
    "        optimizer.first_step(zero_grad=True)\n",
    "\n",
    "        # second forward-backward step\n",
    "        disable_running_stats(model)\n",
    "        smooth_crossentropy(model(inputs), targets, smoothing=label_smoothing).mean().backward()\n",
    "        optimizer.second_step(zero_grad=True)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            correct = torch.argmax(predictions.data, 1) == targets\n",
    "            log(model, loss.cpu(), correct.cpu(), scheduler.lr())\n",
    "            scheduler(epoch)\n",
    "\n",
    "    model.eval()\n",
    "    log.eval(len_dataset=len(dataset.test))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataset.test:\n",
    "            inputs, targets = (b.to(device) for b in batch)\n",
    "\n",
    "            predictions = model(inputs)\n",
    "            loss = smooth_crossentropy(predictions, targets)\n",
    "            correct = torch.argmax(predictions, 1) == targets\n",
    "            log(model, loss.cpu(), correct.cpu())\n",
    "log.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "31758a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), \n",
    "    lr=learning_rate, \n",
    "    weight_decay=weight_decay\n",
    ")\n",
    "scheduler = StepLR(optimizer, learning_rate, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cacce2d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┏━━━━━━━━━━━━━━┳━━━━━━━╸T╺╸R╺╸A╺╸I╺╸N╺━━━━━━━┳━━━━━━━╸S╺╸T╺╸A╺╸T╺╸S╺━━━━━━━┳━━━━━━━╸V╺╸A╺╸L╺╸I╺╸D╺━━━━━━━┓\n",
      "┃              ┃              ╷              ┃              ╷              ┃              ╷              ┃\n",
      "┃       epoch  ┃        loss  │    accuracy  ┃        l.r.  │     elapsed  ┃        loss  │    accuracy  ┃\n",
      "┠──────────────╂──────────────┼──────────────╂──────────────┼──────────────╂──────────────┼──────────────┨\n",
      "┃           0  ┃      1.9893  │     12.52 %  ┃   1.000e-03  │   00:48 min  ┃      2.2263  │     18.26 %  ┃\n",
      "┃           1  ┃      1.6752  │     16.75 %  ┃   1.000e-03  │   00:52 min  ┃      1.6856  │     20.65 %  ┃\n",
      "┃           2  ┃      1.6351  │     18.52 %  ┃   1.000e-03  │   00:58 min  ┃      1.6210  │     18.77 %  ┃\n",
      "┃           3  ┃      1.6303  │     17.93 %  ┃   1.000e-03  │   01:02 min  ┃      1.5918  │     18.63 %  ┃\n",
      "┃           4  ┃      1.6179  │     19.56 %  ┃   1.000e-03  │   01:04 min  ┃      1.5887  │     21.98 %  ┃\n",
      "┃           5  ┃      1.6132  │     19.43 %  ┃   1.000e-03  │   01:07 min  ┃      1.5898  │     17.97 %  ┃\n",
      "┃           6  ┃      1.6096  │     19.17 %  ┃   1.000e-03  │   01:13 min  ┃      1.5842  │     21.69 %  ┃\n",
      "┃           7  ┃      1.6093  │     19.75 %  ┃   1.000e-03  │   01:17 min  ┃      1.5637  │     21.41 %  ┃\n",
      "┃           8  ┃      1.6021  │     19.53 %  ┃   1.000e-03  │   01:28 min  ┃      1.6169  │     21.45 %  ┃\n",
      "┃           9  ┃      1.5999  │     19.25 %  ┃   1.000e-03  │   01:28 min  ┃      1.5641  │     20.58 %  ┃\n",
      "┃          10  ┃      1.5858  │     19.79 %  ┃   1.000e-03  │   01:34 min  ┃      1.5639  │     22.28 %  ┃\n",
      "┃          11  ┃      1.5712  │     21.31 %  ┃   1.000e-03  │   01:48 min  ┃      2.2252  │     23.34 %  ┃\n",
      "┃          12  ┃      1.5499  │     20.70 %  ┃   1.000e-03  │   02:04 min  ┃      3.9527  │     20.90 %  ┃\n",
      "┃          13  ┃      1.5266  │     22.04 %  ┃   1.000e-03  │   02:19 min  ┃      4.3001  │     25.16 %  ┃\n",
      "┃          14  ┃      1.5090  │     23.31 %  ┃   1.000e-03  │   02:36 min  ┃      1.5642  │     24.81 %  ┃\n",
      "┃          15  ┃      1.4944  │     23.71 %  ┃   1.000e-03  │   02:53 min  ┃      1.4807  │     27.90 %  ┃\n",
      "┃          16  ┃      1.4923  │     23.35 %  ┃   1.000e-03  │   03:05 min  ┃      1.4692  │     23.14 %  ┃\n",
      "┃          17  ┃      1.4848  │     23.42 %  ┃   1.000e-03  │   03:26 min  ┃      1.4232  │     25.17 %  ┃\n",
      "┃          18  ┃      1.4805  │     23.93 %  ┃   1.000e-03  │   03:33 min  ┃      1.4325  │     24.36 %  ┃\n",
      "┃          19  ┃      1.4803  │     22.85 %  ┃   1.000e-03  │   03:46 min  ┃      1.4141  │     27.61 %  ┃\n",
      "┃          20  ┃      1.4608  │     23.33 %  ┃   1.000e-03  │   03:49 min  ┃      1.4168  │     26.84 %  ┃\n",
      "┃          21  ┃      1.4471  │     24.13 %  ┃   1.000e-03  │   03:51 min  ┃      1.4025  │     26.51 %  ┃\n",
      "┃          22  ┃      1.4419  │     24.82 %  ┃   1.000e-03  │   03:56 min  ┃      1.4263  │     25.76 %  ┃\n",
      "┃          23  ┃      1.4281  │     25.47 %  ┃   1.000e-03  │   04:20 min  ┃      1.3866  │     28.15 %  ┃\n",
      "┃          24  ┃      1.4235  │     25.53 %  ┃   1.000e-03  │   04:20 min  ┃      1.3781  │     27.24 %  ┃\n",
      "┃          25  ┃      1.4155  │     25.79 %  ┃   1.000e-03  │   04:07 min  ┃      1.4167  │     27.03 %  ┃\n",
      "┃          26  ┃      1.4077  │     25.74 %  ┃   1.000e-03  │   04:23 min  ┃      1.3588  │     27.65 %  ┃\n",
      "┃          27  ┃      1.4512  │     25.00 %  ┃   1.000e-03  │   03:43 min  ┠┈██████████████████████████░┈┨"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/sohom/miniconda3/envs/nnti-project/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/sohom/miniconda3/envs/nnti-project/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/sohom/miniconda3/envs/nnti-project/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/sohom/miniconda3/envs/nnti-project/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-19-5371903f3c4e>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     14\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mno_grad\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     15\u001B[0m             \u001B[0mcorrect\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0margmax\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpredictions\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0mtargets\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 16\u001B[0;31m             \u001B[0mlog\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mloss\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcpu\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcorrect\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcpu\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mscheduler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     17\u001B[0m             \u001B[0mscheduler\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mepoch\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     18\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    log.train(len_dataset=len(dataset.train))\n",
    "    \n",
    "    for batch in dataset.train:\n",
    "        inputs, targets = (b.to(device) for b in batch)\n",
    "\n",
    "        enable_running_stats(model)\n",
    "        predictions = model(inputs)\n",
    "        loss = smooth_crossentropy(predictions, targets, smoothing=label_smoothing)\n",
    "        loss.mean().backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            correct = torch.argmax(predictions.data, 1) == targets\n",
    "            log(model, loss.cpu(), correct.cpu(), scheduler.lr())\n",
    "            scheduler(epoch)\n",
    "\n",
    "    model.eval()\n",
    "    log.eval(len_dataset=len(dataset.test))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataset.test:\n",
    "            inputs, targets = (b.to(device) for b in batch)\n",
    "            predictions = model(inputs)\n",
    "            loss = smooth_crossentropy(predictions, targets)\n",
    "            correct = torch.argmax(predictions, 1) == targets\n",
    "            log(model, loss.cpu(), correct.cpu())\n",
    "log.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eed483c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35c7247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), 'model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5931978",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}