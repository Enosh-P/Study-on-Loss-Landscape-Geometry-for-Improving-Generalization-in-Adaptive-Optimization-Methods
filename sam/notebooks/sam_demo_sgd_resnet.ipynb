{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f35b564",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from model.resnet import ResNet18\n",
    "from model.smooth_cross_entropy import smooth_crossentropy\n",
    "from data.cifar import Cifar\n",
    "from utility.log import Log\n",
    "from utility.step_lr import StepLR\n",
    "from utility.bypass_bn import enable_running_stats, disable_running_stats\n",
    "\n",
    "import sys; sys.path.append(\"..\")\n",
    "from sam import SAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c588d070",
   "metadata": {},
   "outputs": [],
   "source": [
    "adaptive =  True\n",
    "batch_size = 128\n",
    "depth = 16\n",
    "dropout = 0.0\n",
    "epochs = 200\n",
    "label_smoothing = 0.1\n",
    "learning_rate = 0.001\n",
    "momentum= 0.9\n",
    "threads = 5\n",
    "rho = 2.0\n",
    "weight_decay = 0.0005\n",
    "width_factor = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c008c045",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize(seed: int):\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    torch.backends.cudnn.enabled = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cudnn.deterministic = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "892580fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "initialize(seed=42)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7dd42d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "dataset = Cifar(batch_size, threads)\n",
    "log = Log(log_each=10)\n",
    "model = ResNet18(num_classes=10).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95c4e298",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_optimizer = torch.optim.SGD\n",
    "optimizer = SAM(model.parameters(), base_optimizer, rho=rho, adaptive=adaptive, lr=learning_rate, weight_decay=weight_decay, momentum=momentum)\n",
    "scheduler = StepLR(optimizer, learning_rate, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_losses = np.zeros(epochs)\n",
    "train_accuracy = np.zeros(epochs)\n",
    "val_losses = np.zeros(epochs)\n",
    "val_accuracy = np.zeros(epochs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "527b223d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┏━━━━━━━━━━━━━━┳━━━━━━━╸T╺╸R╺╸A╺╸I╺╸N╺━━━━━━━┳━━━━━━━╸S╺╸T╺╸A╺╸T╺╸S╺━━━━━━━┳━━━━━━━╸V╺╸A╺╸L╺╸I╺╸D╺━━━━━━━┓\n",
      "┃              ┃              ╷              ┃              ╷              ┃              ╷              ┃\n",
      "┃       epoch  ┃        loss  │    accuracy  ┃        l.r.  │     elapsed  ┃        loss  │    accuracy  ┃\n",
      "┠──────────────╂──────────────┼──────────────╂──────────────┼──────────────╂──────────────┼──────────────┨\n",
      "┃           0  ┃      1.3440  │     34.53 %  ┃   1.000e-03  │   03:46 min  ┠┈███████████▓┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┨"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"C:\\Users\\enosh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 287, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"C:\\Users\\enosh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 52, in fetch\n    return self.collate_fn(data)\n  File \"C:\\Users\\enosh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 172, in default_collate\n    return [default_collate(samples) for samples in transposed]  # Backwards compatibility.\n  File \"C:\\Users\\enosh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 172, in <listcomp>\n    return [default_collate(samples) for samples in transposed]  # Backwards compatibility.\n  File \"C:\\Users\\enosh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 136, in default_collate\n    storage = elem.storage()._new_shared(numel)\n  File \"C:\\Users\\enosh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\storage.py\", line 487, in _new_shared\n    untyped_storage = module._UntypedStorage._new_shared(size * cls().element_size())\n  File \"C:\\Users\\enosh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\storage.py\", line 172, in _new_shared\n    return cls._new_using_filename(size)\nRuntimeError: Couldn't open shared file mapping: <0000029602774552>, error code: <1455>\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Input \u001B[1;32mIn [7]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      2\u001B[0m model\u001B[38;5;241m.\u001B[39mtrain()\n\u001B[0;32m      3\u001B[0m log\u001B[38;5;241m.\u001B[39mtrain(len_dataset\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mlen\u001B[39m(dataset\u001B[38;5;241m.\u001B[39mtrain))\n\u001B[1;32m----> 5\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m batch \u001B[38;5;129;01min\u001B[39;00m dataset\u001B[38;5;241m.\u001B[39mtrain:\n\u001B[0;32m      6\u001B[0m     inputs, targets \u001B[38;5;241m=\u001B[39m (b\u001B[38;5;241m.\u001B[39mto(device) \u001B[38;5;28;01mfor\u001B[39;00m b \u001B[38;5;129;01min\u001B[39;00m batch)\n\u001B[0;32m      8\u001B[0m     \u001B[38;5;66;03m# first forward-backward step\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:530\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    528\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    529\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()\n\u001B[1;32m--> 530\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    531\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    532\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    533\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    534\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1224\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1222\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1223\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_task_info[idx]\n\u001B[1;32m-> 1224\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_process_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1250\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._process_data\u001B[1;34m(self, data)\u001B[0m\n\u001B[0;32m   1248\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_try_put_index()\n\u001B[0;32m   1249\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data, ExceptionWrapper):\n\u001B[1;32m-> 1250\u001B[0m     \u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreraise\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1251\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m data\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_utils.py:457\u001B[0m, in \u001B[0;36mExceptionWrapper.reraise\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    453\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[0;32m    454\u001B[0m     \u001B[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001B[39;00m\n\u001B[0;32m    455\u001B[0m     \u001B[38;5;66;03m# instantiate since we don't know how to\u001B[39;00m\n\u001B[0;32m    456\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(msg) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m--> 457\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m exception\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"C:\\Users\\enosh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 287, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"C:\\Users\\enosh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 52, in fetch\n    return self.collate_fn(data)\n  File \"C:\\Users\\enosh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 172, in default_collate\n    return [default_collate(samples) for samples in transposed]  # Backwards compatibility.\n  File \"C:\\Users\\enosh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 172, in <listcomp>\n    return [default_collate(samples) for samples in transposed]  # Backwards compatibility.\n  File \"C:\\Users\\enosh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 136, in default_collate\n    storage = elem.storage()._new_shared(numel)\n  File \"C:\\Users\\enosh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\storage.py\", line 487, in _new_shared\n    untyped_storage = module._UntypedStorage._new_shared(size * cls().element_size())\n  File \"C:\\Users\\enosh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\storage.py\", line 172, in _new_shared\n    return cls._new_using_filename(size)\nRuntimeError: Couldn't open shared file mapping: <0000029602774552>, error code: <1455>\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    log.train(len_dataset=len(dataset.train))\n",
    "\n",
    "    for batch in dataset.train:\n",
    "        inputs, targets = (b.to(device) for b in batch)\n",
    "\n",
    "        # first forward-backward step\n",
    "        enable_running_stats(model)\n",
    "        predictions = model(inputs)\n",
    "        loss = smooth_crossentropy(predictions, targets, smoothing=label_smoothing)\n",
    "        loss.mean().backward()\n",
    "        optimizer.first_step(zero_grad=True)\n",
    "\n",
    "        # second forward-backward step\n",
    "        disable_running_stats(model)\n",
    "        smooth_crossentropy(model(inputs), targets, smoothing=label_smoothing).mean().backward()\n",
    "        optimizer.second_step(zero_grad=True)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            correct = torch.argmax(predictions.data, 1) == targets\n",
    "            log(model, loss.cpu(), correct.cpu(), scheduler.lr())\n",
    "            scheduler(epoch)\n",
    "\n",
    "    model.eval()\n",
    "    train_losses[epoch], train_accuracy[epoch] = log.eval(len_dataset=len(dataset.test))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataset.test:\n",
    "            inputs, targets = (b.to(device) for b in batch)\n",
    "\n",
    "            predictions = model(inputs)\n",
    "            loss = smooth_crossentropy(predictions, targets)\n",
    "            correct = torch.argmax(predictions, 1) == targets\n",
    "            log(model, loss.cpu(), correct.cpu())\n",
    "            if epoch > 0:\n",
    "                val_losses[epoch-1] = log.current_valid_loss\n",
    "                val_accuracy[epoch-1] = log.current_valid_accuracy\n",
    "\n",
    "val_losses[epochs-1] = log.current_valid_loss\n",
    "val_accuracy[epochs-1] = log.current_valid_accuracy\n",
    "\n",
    "log.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f6018d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'sam_model_sgd_resnet.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(range(1, epochs + 1), train_losses, label='Train loss')\n",
    "plt.plot(range(1, epochs + 1), val_losses, label='Validation loss')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(range(1, epochs + 1), train_accuracy, label='Train Accuracy')\n",
    "plt.plot(range(1, epochs + 1), val_accuracy, label='Train Accuracy')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}